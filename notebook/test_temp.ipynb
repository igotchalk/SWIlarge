{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly running run_SEAWAT_MC_NM.py to reproduce hanging at Stress Per 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../data/PriorModel/varlist.pkl\n",
      "loading...\n",
      "unpacking and setting vars...\n",
      "creating objs...\n",
      "WARNING: unit 15 of package LPF already in use\n",
      "****Warning -- two packages of the same type:  <class 'flopy.modflow.mflpf.ModflowLpf'> <class 'flopy.modflow.mflpf.ModflowLpf'>\n",
      "replacing existing Package...\n",
      "WARNING: unit 31 of package BTN already in use\n",
      "****Warning -- two packages of the same type:  <class 'flopy.mt3d.mtbtn.Mt3dBtn'> <class 'flopy.mt3d.mtbtn.Mt3dBtn'>\n",
      "replacing existing Package...\n",
      "WARNING: unit 33 of package DSP already in use\n",
      "****Warning -- two packages of the same type:  <class 'flopy.mt3d.mtdsp.Mt3dDsp'> <class 'flopy.mt3d.mtdsp.Mt3dDsp'>\n",
      "replacing existing Package...\n",
      "WARNING: unit 24 of package CHD already in use\n",
      "****Warning -- two packages of the same type:  <class 'flopy.modflow.mfchd.ModflowChd'> <class 'flopy.modflow.mfchd.ModflowChd'>\n",
      "replacing existing Package...\n"
     ]
    }
   ],
   "source": [
    "import flopy\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "########## INPUT #############\n",
    "# it = int(sys.argv[1])-1\n",
    "# f_varlist = Path(sys.argv[2])\n",
    "\n",
    "it=0\n",
    "f_varlist = Path('../data/PriorModel/varlist.pkl')\n",
    "print(it,f_varlist)\n",
    "\n",
    "########## INPUT #############\n",
    "\n",
    "\n",
    "if sys.platform.lower()=='linux':\n",
    "    datadir = Path('/scratch/users/ianpg/SWIlarge/data')\n",
    "    workdir = Path('/scratch/users/ianpg/SWIlarge/work')\n",
    "    MPSdir = datadir.joinpath('lith/sgems/MPS')\n",
    "    lithdir = datadir.joinpath('lith/sgems/')\n",
    "    GISdir = datadir.joinpath('GIS')\n",
    "    priordir = datadir.joinpath('PriorModel')\n",
    "    modeldir = datadir.joinpath('NM_model')\n",
    "elif sys.platform.lower()=='darwin':\n",
    "    datadir = Path('../data')\n",
    "    workdir = Path('../work')\n",
    "    MPSdir = Path('/Users/ianpg/Dropbox/temp_convenience/SWIlarge/data/lith/sgems/MPS')\n",
    "    GISdir = datadir.joinpath('GIS')\n",
    "    lithdir = datadir.joinpath('lith/sgems/')\n",
    "    priordir = datadir.joinpath('PriorModel')\n",
    "    modeldir = datadir.joinpath('NM_model')\n",
    "\n",
    "nmgwmdir_empty = datadir.joinpath('nmgwmdir_empty') #<-- removed everything but DIS\n",
    "nmgwmdir_cal = datadir.joinpath('Calibrated_small') #<-- removed RCH, WEL, GLO, LST from the NAM file to load much faster\n",
    "figdir = workdir.joinpath('figs')\n",
    "outputdir = workdir.joinpath('output')\n",
    "\n",
    "import config\n",
    "import utils\n",
    "\n",
    "\n",
    "#%% Useful functions\n",
    "def load_obj(dirname,name):\n",
    "    import pickle\n",
    "    with open(Path(dirname).joinpath(name + '.pkl').as_posix(), 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def save_obj(dirname,obj,name):\n",
    "    import pickle\n",
    "    with open(Path(dirname).joinpath(name + '.pkl').as_posix(), 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def make_timestamp(YMD=True,HM=True):\n",
    "    import datetime\n",
    "    if YMD:\n",
    "        ymd = '%Y%m%d'\n",
    "    else:\n",
    "        ymd = ''\n",
    "    if HM:\n",
    "        hm = '%H%M'\n",
    "    else:\n",
    "        hm = ''\n",
    "    if YMD and HM:\n",
    "        sep = '_'\n",
    "    else:\n",
    "        sep = ''\n",
    "    return datetime.datetime.now().strftime('{}{}{}'.format(ymd,sep,hm))\n",
    "\n",
    "\n",
    "\n",
    "if len(f_varlist.name.split('.'))>1:\n",
    "    nam = f_varlist.name.split('.')[0]\n",
    "else:\n",
    "    nam = f_varlist.name\n",
    "varlist = load_obj(f_varlist.parent,nam)\n",
    "ts = make_timestamp()\n",
    "\n",
    "print('loading...')\n",
    "##Loading\n",
    "modelname = 'NM'\n",
    "model_ws = workdir.joinpath('NM_{}'.format(it))\n",
    "\n",
    "\n",
    "m= flopy.seawat.Seawat.load(modelname + '.nam',exe_name=config.swexe, model_ws=model_ws.as_posix())\n",
    "rows = np.load(model_ws.joinpath('rows.npy'))\n",
    "starttime = np.load(model_ws.joinpath('starttime.npy'))\n",
    "layer_mapping_ind_full = np.load(GISdir.joinpath('layer_mapping_ind_full.npy'))                                 \n",
    "layer_mapping_ind = layer_mapping_ind_full[:,rows,:]\n",
    "# m = flopy.seawat.Seawat(modelname, exe_name=config.swexe, model_ws=model_ws.as_posix(),verbose=verbose)\n",
    "\n",
    "\n",
    "# ##Make temp folder for writing\n",
    "# model_ws = workdir.joinpath('NM_{}'.format(it))\n",
    "# if not model_ws.exists():\n",
    "#     model_ws.mkdir()\n",
    "# m.model_ws = model_ws.as_posix()\n",
    "\n",
    "\n",
    "print('unpacking and setting vars...')\n",
    "\n",
    "##Unpack vars\n",
    "por_sand = varlist['por_sand'][it] #done\n",
    "por_clay = varlist['por_clay'][it] #done\n",
    "aL = varlist['aL'][it] #done\n",
    "kvh = varlist['kvh'][it] #done\n",
    "kh_sand_180 = varlist['kh_sand_180'][it] #done\n",
    "kh_clay_180 = varlist['kh_clay_180'][it] #done\n",
    "kh_sand_400 = varlist['kh_sand_400'][it] #done\n",
    "kh_clay_400 = varlist['kh_clay_400'][it] #done\n",
    "kh_lay1     = varlist['kh_lay1'][it] #done \n",
    "DSA_head    = varlist['DSA_head'][it] #done \n",
    "\n",
    "\n",
    "hk_aquitard = min(kh_clay_180,kh_clay_400)\n",
    "hk = np.zeros_like(layer_mapping_ind_full,dtype=np.float)\n",
    "lith_180 = np.load(lithdir.joinpath('snesim','mps180_{}.npy'.format(it))).astype(np.float)\n",
    "lith_400 = np.load(lithdir.joinpath('sisim','sisim400_{}.npy'.format(it))).astype(np.float)\n",
    "\n",
    "\n",
    "\n",
    "lith_180[lith_180==1.] = kh_sand_180\n",
    "lith_180[lith_180==0.] = kh_clay_180\n",
    "lith_400[lith_400==1.] = kh_sand_400\n",
    "lith_400[lith_400==0.] = kh_clay_400\n",
    "\n",
    "\n",
    "hk[np.where(layer_mapping_ind_full==0)] = 10000\n",
    "hk[np.where(layer_mapping_ind_full==1)] = kh_lay1\n",
    "hk[np.where(layer_mapping_ind_full==2)] = hk_aquitard\n",
    "hk[np.where(layer_mapping_ind_full==3)] = lith_180[np.where(layer_mapping_ind_full==3)]\n",
    "hk[np.where(layer_mapping_ind_full==4)] = hk_aquitard\n",
    "hk[np.where(layer_mapping_ind_full==5)] = lith_400[np.where(layer_mapping_ind_full==5)]\n",
    "hk[np.where(layer_mapping_ind_full>5)] = 1.\n",
    "\n",
    "prsity = np.zeros_like(layer_mapping_ind_full,dtype=np.float)\n",
    "prsity[np.isin(hk,(kh_lay1,kh_sand_180,kh_sand_400))]=por_sand\n",
    "prsity[np.where(prsity==0.)]=por_clay\n",
    "\n",
    "\n",
    "hk = hk[:,rows,:]\n",
    "prsity = prsity[:,rows,:]\n",
    "\n",
    "\n",
    "chd_data_orig = m.chd.stress_period_data\n",
    "chd_data = {}\n",
    "for per in range(m.dis.nper):\n",
    "    chd_per=[]\n",
    "    for val in chd_data_orig.data[0]:\n",
    "        chd_per.append([val[0],val[1],val[2],DSA_head,DSA_head])\n",
    "    chd_data[per] = chd_per\n",
    "    \n",
    "print('creating objs...')\n",
    "\n",
    "lpf = flopy.modflow.ModflowLpf(m, hk=hk, vka=kvh, ipakcb=m.lpf.ipakcb,laytyp=0,laywet=0,\n",
    "                              ss=m.lpf.ss.array,sy=m.lpf.sy.array)\n",
    "\n",
    "try:\n",
    "    sconc= m.btn.sconc.array\n",
    "except:\n",
    "    sconc= m.btn.sconc[0].array\n",
    "btn = flopy.mt3d.Mt3dBtn(m,\n",
    "                         laycon=m.btn.laycon.array, htop=m.btn.htop.array,\n",
    "                         dz=m.dis.thickness.get_value(), prsity=prsity, icbund=m.btn.icbund.array,\n",
    "                         sconc=sconc, nprs=1,timprs=m.btn.timprs)\n",
    "\n",
    "dsp = flopy.mt3d.Mt3dDsp(m, al=aL,dmcoef=2.0e-9)\n",
    "chd = flopy.modflow.ModflowChd(m, stress_period_data=chd_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "writeyn= True\n",
    "runyn = True\n",
    "#Write input\n",
    "if writeyn:\n",
    "    print('writing...')\n",
    "    m.write_input()\n",
    "    \n",
    "    \n",
    "# Try to delete the output files, to prevent accidental use of older files\n",
    "f_delete = [os.path.join(m.model_ws,'MT3D.CNF'),\n",
    "            os.path.join(m.model_ws,'MT3D001.MAS'),\n",
    "            os.path.join(m.model_ws, 'MT3D001.UCN'),\n",
    "            os.path.join(m.model_ws, modelname + '.hds'),\n",
    "            os.path.join(m.model_ws, modelname + '.cbc')]\n",
    "\n",
    "for f in f_delete:\n",
    "    try:\n",
    "        os.remove(f)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#%%\n",
    "\n",
    "if runyn:\n",
    "    print('running...')\n",
    "    v = m.run_model(silent=False, report=True)\n",
    "    for idx in range(-3, 0):\n",
    "        print(v[1][idx])\n",
    "else:\n",
    "    print('Not running model!')\n",
    "\n",
    "exportdir = outputdir.joinpath('NM')\n",
    "if not exportdir.exists():\n",
    "    exportdir.mkdir(parents=True)\n",
    "\n",
    "date_per = starttime + np.cumsum(m.dis.perlen.array)/365\n",
    "survey_date = 2017.25\n",
    "survey_kper = np.argmin(np.abs(date_per-survey_date))\n",
    "\n",
    "fname = os.path.join(m.model_ws, 'MT3D001.UCN')\n",
    "totim = flopy.utils.binaryfile.UcnFile(fname).get_times()[-1]\n",
    "conc_fname = 'conc{}_{}_totim{}.UCN'.format(\n",
    "    it, ts, str(int(totim)))\n",
    "\n",
    "utils.copy_rename(fname,\n",
    "                 exportdir.joinpath(conc_fname))\n",
    "conc = flopy.utils.binaryfile.UcnFile(fname).get_data(kstpkper=(0,survey_kper))\n",
    "np.save(exportdir.joinpath(conc_fname[:-4] + '.npy'),conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "copying from ../work/NM to ../work/NM_0 \n",
      "1\n",
      "copying from ../work/NM to ../work/NM_1 \n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "model_ws_orig = workdir.joinpath('NM')\n",
    "for it in range(0,2):\n",
    "    print(it)\n",
    "    dst = model_ws_orig.parent.joinpath(model_ws_orig.name + '_{}'.format(it))\n",
    "    if dst.exists():\n",
    "        shutil.rmtree(dst)\n",
    "    print('copying from {} to {} '.format(model_ws_orig,dst))\n",
    "    shutil.copytree(model_ws_orig.as_posix(),dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SWIenv]",
   "language": "python",
   "name": "conda-env-SWIenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
